# Generative AI with Large Language Models


This repo contains laboratories and assignements from the course **[Generative AI with Large Language Models](https://www.coursera.org/learn/generative-ai-with-llms/home/info)** offered by [deeplearning.ai](https://deeplearning.ai/)

## Week 1: Introduction to LLMs and the generative AI project lifecycle

### Lab 1: Generative AI Use Case: Summarize Dialogue

> In this lab, you will do the dialogue summarization task using generative AI. You will explore how the input text affects the output of the model, and perform prompt engineering to direct it towards the task you need. By comparing zero shot, one shot, and few shot inferences, you will take the first step towards prompt engineering and see how it can enhance the generative output of Large Language Models.  

### Lab 2: Fine-Tune a Generative AI Model for Dialogue Summarization

> In this notebook, you will fine-tune an existing LLM from Hugging Face for enhanced dialogue summarization. You will use the [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5) model, which provides a high quality instruction tuned model and can summarize text out of the box. To improve the inferences, you will explore a full fine-tuning approach and evaluate the results with ROUGE metrics. Then you will perform Parameter Efficient Fine-Tuning (PEFT), evaluate the resulting model and see that the benefits of PEFT outweigh the slightly-lower performance metrics.